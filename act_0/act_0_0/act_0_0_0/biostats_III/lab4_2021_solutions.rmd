---
title: "140.653 Lab 4: Bootstrap"
author: "Erjia Cui & Elizabeth Colantuoni"
output: html_document
---

```{r,message=FALSE,warning=FALSE}
library(ggplot2)
library(boot)
```

Bootstrap is a method of inference about a population using sample data. The idea was firstly introduced by Bradley Efron in 1979. The bootstrap relies on **sampling with replacement** from sample data. This technique can be used to estimate the standard error of any statistic (function of the observations) and to obtain a confidence interval (CI) for the population analogue. Bootstrap is especially useful when the statistic is a complex function of the data so that standard errors (CIs) can not derived in closed form. Here, we use the `iris` dataset to illustrate this bootstrap ideas.

Our question: how strongly is Sepal length associated with Sepal width for each of the species. Because the data are not well approximated by the Gaussian distribution, we will measure association by Spearman's rank correlation, which is obtained by replacing the two variables by their ranks and measuring the Pearson correlation between the ranks. As a result, the Spearman rank coefficient is a highly non-linear function of the original data. 

```{r}
head(iris)
```


### Example 

The goal is to compare Spearman's rank correlations across three species. We use the function `boot()` from the `boot` package for bootstraping. This function can do both parametric and nonparametric bootstraping. It automatically resamples the observations from the given dataset for given number of times, and directly gives you the bootstraped statistic.

Therefore, in our example, you have to specify your dataset (data), your statistic of interest (statistic as an R function) and number of repetition (R).

```{r}
?boot # description for components in boot

# function that takes a data frame as a input and gives estimated statistic
bt.est <- function(data, indices){
    dt <- data[indices,] # allows boot to select sample
    cor1 <- cor(dt$Sepal.Length[dt$Species=="setosa"], dt$Sepal.Width[dt$Species=="setosa"], method='s')
    cor2 <- cor(dt$Sepal.Length[dt$Species=="versicolor"], dt$Sepal.Width[dt$Species=="versicolor"], method='s')
    cor3 <- cor(dt$Sepal.Length[dt$Species=="virginica"], dt$Sepal.Width[dt$Species=="virginica"], method='s')
    
    c(cor1,cor2,cor3)
}

set.seed(123)
result <- boot(iris, bt.est, R=1000)
str(result)
```

The element `$t` contains a total number of R values (i.e. number of repetitions) for each statistic generated by the bootstrap procedure:

````{r}
dim(result$t)
head(result$t)

# histogram
par(mfrow=c(2,2))
hist(result$t[,1],breaks = 20,main = 'Correlation for setosa',xlab = 'bootstrapped corr')
hist(result$t[,2],breaks = 20,main = 'Correlation for versicolor',xlab = 'bootstrapped corr')
hist(result$t[,3],breaks = 20,main = 'Correlation for virginica',xlab = 'bootstrapped corr')
```

We can observe some skew pattern (not normal) for distribution of bootstrapped spearman correlation for `setosa`. Therefore, we choose percentile method (not assuming normality for the tatistic) instead of using wald method (assuming normality) to obtain CI.


#### The bias-corrected and accelerated (BCa) bootstrap CI

The `boot.ci()` function gives 5 different types of CIs, including the wald bootstrap interval, the bootstrap percentile interval, and the adjusted bootstrap percentile (BCa) interval. Here we use BCa CI. The main advantage to the BCa interval is that it corrects for bias and skewness in the distribution of bootstrap estimates. (link: https://www.datacamp.com/community/tutorials/bootstrap-r) 

```{r}
boot.perc.ci <- sapply(1:3,function(x) boot.ci(result,index = x,type = "bca")$bca[4:5])
boot.result <- data.frame(rbind(result$t0,boot.perc.ci))
rownames(boot.result) <- c("Est","Lower","Upper")
colnames(boot.result) <- c('setosa','versicolor','virginica')
round(boot.result,3)
```

```{r}
ggplot(iris,aes(x=Sepal.Width,y=Sepal.Length,color = Species)) + 
    theme_bw() +
    geom_point() +
    geom_smooth(method="lm") +
    annotate("text", x = 3, y = 8, label = paste0("Cor = ",round(boot.result$virginica[1],3)),col='#619CFF') +
    annotate("text", x = 3.7, y = 6, label = paste0("Cor = ",round(boot.result$versicolor[1],3)),col='#00BA38') +
    annotate("text", x = 4, y = 4.5, label = paste0("Cor = ",round(boot.result$setosa[1],3)),col ='#F8766D')
```

### In class exercise: Using **nepal.anthro** dataset

In Lecture 6 and 7, we showed that $\hat{\beta_0}$, $\hat{\beta_1}$, and $\hat{\beta_2}$ are normally distributed under the assumption of Gaussian residuals. In Lecture 7 we evaluated the sensitivity of this assumption to violations of this normality assumption. Here we are **not relying on the normality assumption** but generating the sampling distributions for parameters of interest to make inferences.

 **Goal: Generate 95% bootstrapped CIs for (1) the linear slope for age for children under 6 months ($\hat{\beta_1}$); (2) the linear slope for age for children over 6 months ($\hat{\beta_1}$+$\hat{\beta_2}$); (3) the relative rate of growth comparing over 6 months to under 6 months ($(\hat{\beta}_1 + \hat{\beta}_2) / \hat{\beta}_1$).**

The model is:
$$
E(Y_i|age_i) = \beta_0 + \beta_1 \cdot age_i + \beta_2 \cdot (age_i-6)^+
$$

**1. Model**

```{r}
load('./../nepal.anthro.rdata')

# extract first visit data per child
dat <- nepal.anthro[nepal.anthro$fuvisit==0,] # 200 observations
dat$age_sp6 <- ifelse(dat$age>6, dat$age-6, 0)
fit <- lm(arm ~ age + age_sp6, data = dat)
summary(fit)
```

**2. Key steps**

* Bootstrapp R = 1000 times (Sampling with replacement)
* Compute the statistic
* Store bootstrapped statistic into a data frame or matrix
* Choose reasonable bootstrapped CI method for the statistic


```{r}
# function that takes a data frame as a input and gives estimated statistic
age.est <- function(data, id){
    dt <- data[id,]
    fit1 <- lm(arm ~ age + age_sp6, data = dt)
    beta.under6 <- coef(fit1)[2]
    beta.over6 <- coef(fit1)[2] + coef(fit1)[3]
    rate <- beta.over6 / beta.under6
    c(beta.under6,beta.over6,rate)
}

set.seed(123)
nepal.result <- boot(dat, age.est, R=1000)

# Under the assumption of normal residual
nepal.boot.perc.ci <- sapply(1:3,function(x) boot.ci(nepal.result,index = x,type = "bca")$bca[4:5]) # can also use wald type CI
nepal.boot.result <- data.frame(rbind(nepal.result$t0,nepal.boot.perc.ci))
rownames(nepal.boot.result) <- c("Est","Lower","Upper")
colnames(nepal.boot.result) <- c('coef.under6','coef.over6','coef.rate')
round(nepal.boot.result, 3)

```

```{r}
## compare with 95% CI for beta1 and beta1+beta2 using the model output.

beta.hat <- coef(fit)
cov.mat <- vcov(fit)

## organize into a data frame
beta1.model <- c(Est = beta.hat[2],
                         Lower = beta.hat[2] - 1.96 * sqrt(cov.mat[2,2]),
                         Upper = beta.hat[2] + 1.96 * sqrt(cov.mat[2,2]))
beta12.model <- c(Est = beta.hat[2] + beta.hat[3],
                         Lower = beta.hat[2] + beta.hat[3] - 1.96 * sqrt(cov.mat[2,2] + cov.mat[3,3] + 2*cov.mat[2,3]),
                         Upper = beta.hat[2] + beta.hat[3] + 1.96 * sqrt(cov.mat[2,2] + cov.mat[3,3] + 2*cov.mat[2,3]))
model.output <- cbind(coef.under6.model = beta1.model,coef.over6.model = beta12.model)
rownames(model.output) <- c('Est','Lower','Upper')
round(model.output,3)

## compare
comp <- cbind(nepal.boot.result,model.output)
round(comp, 3)
```

What can you observe from the comparison between bootstrapped CI and model based CI?

```{r}
hist(nepal.result$t[,1], breaks = 20, xlab = "bootstrapped estimates", main = expression(hat(beta)[1]))
```

